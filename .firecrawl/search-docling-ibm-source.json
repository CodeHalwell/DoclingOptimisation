{"success":true,"data":{"web":[{"url":"https://github.com/docling-project/docling-ibm-models","title":"docling-project/docling-ibm-models - GitHub","description":"Layout model is an AI model that provides among other things ability to detect tables on the page. This package contains inference code for Layout model.","position":1,"category":"github"},{"url":"https://github.com/microsoft/onnxruntime","title":"microsoft/onnxruntime: ONNX Runtime: cross-platform, high ... - GitHub","description":"ONNX Runtime is a cross-platform inference and training machine-learning accelerator. ONNX Runtime inference can enable faster customer experiences and lower ...","position":2,"category":"github"},{"url":"https://onnxruntime.ai/docs/build/inferencing.html","title":"Build for inferencing | onnxruntime","description":"Build ONNX Runtime for inferencing. Follow the instructions below to build ONNX Runtime to perform inference.","position":3},{"url":"https://github.com/Microsoft/onnxruntime/blob/master/onnxruntime/core/session/inference_session.h","title":"onnxruntime/onnxruntime/core/session/inference_session.h at main","description":"* Load an ONNX or ORT format model. *. * Set SessionOptions session config value ORT_SESSION_OPTIONS_CONFIG_LOAD_MODEL_FORMAT to 'ORT' or 'ONNX' to.","position":4,"category":"github"},{"url":"https://github.com/microsoft/onnxruntime-extensions","title":"onnxruntime-extensions: A specialized pre- and post - GitHub","description":"ONNXRuntime-Extensions is a C/C++ library that extends the capability of the ONNX models and inference with ONNX Runtime, via ONNX Runtime Custom Operator ABIs.","position":5,"category":"github"}]}}