{"success":true,"data":{"web":[{"url":"https://medium.com/@matiasmaquieira96/the-37-performance-boost-youre-missing-how-pytorch-2-6-s-torch-compile-transforms-your-rnns-265916d63c6a","title":"How PyTorch 2.6's torch.compile Transforms Your RNNs - Medium","description":"PyTorch 2.6 brought significant RNN improvements, but the roadmap for 2025 is even more exciting. FlexAttention for Sequence Models. PyTorch 2.5 ...","position":1},{"url":"https://github.com/pytorch/pytorch/issues/168042","title":"TorchInductor compile breaks when called in a multithreaded ...","description":"TorchInductor compile breaks when called in a multithreaded context with GIL off #168042. New issue.","position":2,"category":"github"},{"url":"https://pytorch.org/blog/pytorch-2-8/","title":"PyTorch 2.8 Release Blog","description":"Inductor CUTLASS backend support for both torch.compile and AOTInductor, as well as GEMMs such as mm, fp8 mm, addmm, and bmm. and more! See ...","position":3},{"url":"https://blog.vllm.ai/2025/08/20/torch-compile.html","title":"Introduction to torch.compile and How It Works with vLLM","description":"For vLLM, the de-facto open-source inference engine for portable and efficient LLM inference, torch.compile isn't just a performance enhancer.","position":4},{"url":"https://blog.ezyang.com/2025/08/state-of-torch-compile-august-2025/","title":"State of torch.compile for training (August 2025)","description":"torch.compile CUDA graphs is typically used with Inductor but we also offer an eager-only cudagraphs integration (that is less well exercised).","position":5}]}}